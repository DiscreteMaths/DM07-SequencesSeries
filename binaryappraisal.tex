


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Performance of Classification Procedure}
	
	These classifications are used to calculate accuracy, precision (also called positive predictive value), recall (also called sensitivity), specificity and negative predictive value:
	
	\begin{itemize}
		\item  \textbf{Accuracy} is the fraction of observations with correct predicted classification
		\[ \mbox{Accuracy}=\frac{TP+TN}{TP+FP+FN+TN}\]
		
		
		\item \textbf{Precision} is the proportion of predicted positives that are correct
		\[
		\mbox{Precision} = \mbox{Positive Predictive Value} =\frac{TP}{TP+FP} \, \]
		
		\item \textbf{Negative Predictive Value} is the  fraction of predicted negatives that are correct
		\[\mbox{Negative Predictive Value} = \frac{TN}{TN+FN}\]
		
		\item \textbf{Recall} is the fraction of observations that are actually 1 with a correct predicted classification
		\[ 
		\mbox{Recall} = \mbox{Sensitivity} = \frac{TP}{TP+FN} \,  \]
		
		\item \textbf{Specificity} is the fraction of observations that are actually 0 with a correct predicted classification
		\[ \mbox{Specificity} = \frac{TN}{TN+FP} \]
		
	\end{itemize}


